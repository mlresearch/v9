---
title: Reduced-Rank Hidden Markov Models
abstract: Hsu et al. (2009) recently proposed an efficient, accurate spectral learning
  algorithm for Hidden Markov Models (HMMs). In this paper we relax their assumptions
  and prove a tighter finite-sample error bound for the case of Reduced-Rank HMMs,
  i.e., HMMs with low-rank transition matrices. Since rank-$k$ RR-HMMs are a larger
  class of models than $k$-state HMMs while being equally efficient to work with, this
  relaxation greatly increases the learning algorithmâ€™s scope. In addition, we generalize
  the algorithm and bounds to models where multiple observations are needed to disambiguate
  state, and to models that emit multivariate real-valued observations. Finally we
  prove consistency for learning Predictive State Representations, an even larger
  class of models. Experiments on synthetic data and a toy video, as well as on difficult
  robot vision data, yield accurate models that compare favorably with alternatives
  in simulation quality and prediction accuracy.
pdf: http://proceedings.mlr.press/v9/siddiqi10a/siddiqi10a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: siddiqi10a
month: 0
tex_title: Reduced-Rank Hidden Markov Models
firstpage: 741
lastpage: 748
page: 741-748
order: 741
cycles: false
author:
- given: Sajid
  family: Siddiqi
- given: Byron
  family: Boots
- given: Geoffrey
  family: Gordon
date: 2010-03-31
address: Chia Laguna Resort, Sardinia, Italy
publisher: PMLR
container-title: Proceedings of the Thirteenth International Conference on Artificial
  Intelligence and Statistics
volume: '9'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 3
  - 31
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

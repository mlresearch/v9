---
title: On the Convergence Properties of Contrastive Divergence
abstract: Contrastive Divergence (CD) is a popular method for estimating the parameters
  of Markov Random Fields (MRFs) by rapidly approximating an intractable term in the
  gradient of the log probability. Despite CD’s empirical success, little is known
  about its theoretical convergence properties. In this paper, we analyze the CD$_1$
  update rule for Restricted Boltzmann Machines (RBMs) with binary variables. We show
  that this update is not the gradient of any function, and construct a counterintuitive
  “regularization function” that causes CD learning to cycle indefinitely.  Nonetheless,
  we show that the regularized CD update has a fixed point for a large class of regularization
  functions using Brower’s fixed point theorem.
pdf: http://proceedings.mlr.press/v9/sutskever10a/sutskever10a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: sutskever10a
month: 0
tex_title: On the Convergence Properties of Contrastive Divergence
firstpage: 789
lastpage: 795
page: 789-795
order: 789
cycles: false
author:
- given: Ilya
  family: Sutskever
- given: Tijmen
  family: Tieleman
date: 2010-03-31
address: Chia Laguna Resort, Sardinia, Italy
publisher: PMLR
container-title: Proceedings of the Thirteenth International Conference on Artificial
  Intelligence and Statistics
volume: '9'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 3
  - 31
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
